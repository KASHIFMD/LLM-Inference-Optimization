servers:
  gpu_servers:
    - name: "GPU_Server_1"
      host: "A.B.C.D"
      port: 22
      containers:
        - name: "image_relevancy"
          process: "image_relevancy"
          image: "image_relevancy"
          port: 5008
          workers: 1       # Less intensive, 2 workers
          threads: 1
          gpu_limit: 35 # Memory limit per container process in GB
          environment:
            # CUDA_VISIBLE_DEVICES: "3,4"  # Restrict to GPU 1
            PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
          restart_policy: "unless-stopped"
